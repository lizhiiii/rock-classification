{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f595d9-343a-4366-ae30-46799534214b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda | GPU: NVIDIA L20\n"
     ]
    }
   ],
   "source": [
    "# rock_hier_train_v2.py  ‚îÄ‚îÄ ConvNeXtV2-Large + ÂèåÂ§¥Â±ÇÊ¨°ÂàÜÁ±ª (ÊîπËøõÁâà)\n",
    "# ==============================================================\n",
    "# 1. Ê†áÂáÜÂ∫ì & Âü∫Á°ÄËÆæÁΩÆ\n",
    "# --------------------------------------------------------------\n",
    "import os, math, time, random, warnings, pathlib\n",
    "import platform, psutil, csv\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "import timm\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import platform\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Êï∞ÊçÆÂ§ÑÁêÜ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Á¨¨‰∏âÊñπSOTAÊ®°Âûã/Â∑•ÂÖ∑ÂåÖ\n",
    "import timm  # È°∂Á∫ßSOTAÊ®°ÂûãÂ∫ìÔºåÂÆûÈôÖÂ•ΩÂÉèÊúçÂä°Âô®Áøª‰∏ç‰∫ÜÂ¢ô\n",
    "\n",
    "# PyTorchÂèäÁîüÊÄÅ\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ÂèØËßÜÂåñ\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ê∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉÊèêÈÄüÁúÅÊòæÂ≠ògradÈò≤Ê≠¢ÂçäÁ≤æÂ∫¶Êï∞ÂÄº‰∏çÁ®≥ÂÆöÔºåÊªëÂä®Âπ≥ÂùáËÉΩÊèê‰æõÊ≥õÂåñËÉΩÂäõ\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "# ËøõÂ∫¶Êù°\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 114514\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.benchmark, torch.backends.cudnn.deterministic = True, False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE} | GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d8a94c-00e1-41c2-93fb-ca9dbccc4e0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 2. Êï∞ÊçÆË∑ØÂæÑ & Ë∂ÖÂèÇÊï∞\n",
    "# --------------------------------------------------------------\n",
    "DATA_ROOT   = \"/shareddata/project/dataset\"\n",
    "TRAIN_CSV   = f\"{DATA_ROOT}/train_val/train_labels.csv\"\n",
    "VAL_CSV     = f\"{DATA_ROOT}/train_val/val_labels.csv\"\n",
    "IMG_DIR_T   = f\"{DATA_ROOT}/train_val/train\"\n",
    "IMG_DIR_V   = f\"{DATA_ROOT}/train_val/val\"\n",
    "TEST_IMGDIR = f\"{DATA_ROOT}/test/test_images\"\n",
    "TEST_CSV    = f\"{DATA_ROOT}/test/test_ids.csv\"\n",
    "\n",
    "NUM_PARENT  = 3\n",
    "BATCH_SIZE  = 64 #Âç†Áî®ÊòæÂ≠ò43977MiB /  46068MiB\n",
    "NUM_EPOCHS  = 60 #Êó©ÂÅúÊó†ÊâÄË∞ì        \n",
    "MIXUP_CUTMIX_STOP = int(NUM_EPOCHS * 0.8)   # Âêé 20% epoch ÂÖ≥Èó≠ MixUp/CutMix\n",
    "BASE_LR     = 2e-4 \n",
    "WARM_EPOCHS = 5\n",
    "WEIGHT_DECAY= 1e-4\n",
    "MAX_GRAD_NORM = 1.0\n",
    "EMA_DECAY  = 0.9999\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0344a9-f324-465a-a09b-e674e282c42f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=102213, val=15000, child=19160\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 3. Êï∞ÊçÆÂ¢ûÂº∫ & Dataset\n",
    "# --------------------------------------------------------------\n",
    "import torchvision.transforms as T\n",
    "MEAN = [0.46798, 0.45764, 0.44035]\n",
    "STD  = [0.18461, 0.18712, 0.19482]\n",
    "\n",
    "tf_train = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandAugment(num_ops=2, magnitude=8),  # Áï•ÈôçÂπÖÂ∫¶\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(MEAN, STD),\n",
    "])\n",
    "tf_eval = T.Compose([\n",
    "    T.Resize(256), T.CenterCrop(224),\n",
    "    T.ToTensor(),  T.Normalize(MEAN, STD)\n",
    "])\n",
    "\n",
    "class RockDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.paths = df[\"id\"].values\n",
    "        self.p_labels = df[\"label\"].values.astype(np.int64)\n",
    "        self.c_labels = pd.factorize(df[\"sublabel\"])[0].astype(np.int64)\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.img_dir, self.paths[idx])).convert(\"RGB\")\n",
    "        return self.transform(img), self.p_labels[idx], self.c_labels[idx]\n",
    "\n",
    "train_ds, val_ds = RockDataset(TRAIN_CSV, IMG_DIR_T, tf_train), RockDataset(VAL_CSV, IMG_DIR_V, tf_eval)\n",
    "NUM_CHILD = int(train_ds.c_labels.max()) + 1\n",
    "print(f\"Dataset: train={len(train_ds)}, val={len(val_ds)}, child={NUM_CHILD}\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, BATCH_SIZE, shuffle=True,  num_workers=8, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141547dc-6140-4e99-ab84-b59599fe6280",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 4. Ê®°ÂûãÂÆö‰πâ (ConvNeXtV2-Large ‰∏ªÂπ≤ + ÂèåÂ§¥)\n",
    "# --------------------------------------------------------------\n",
    "CKPT_PATH  = \"convnextv2_large.fcmae_ft_in22k_in1k_384.bin\"\n",
    "MODEL_NAME = \"convnextv2_large.fcmae_ft_in22k_in1k_384\"\n",
    "\n",
    "state_dict = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"head.\")}\n",
    "backbone   = timm.create_model(MODEL_NAME, pretrained=False, num_classes=0)\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "feat_dim   = backbone.num_features\n",
    "\n",
    "head_parent = nn.Linear(feat_dim, NUM_PARENT)\n",
    "head_child  = nn.Linear(feat_dim, NUM_CHILD)\n",
    "\n",
    "backbone, head_parent, head_child = backbone.to(DEVICE), head_parent.to(DEVICE), head_child.to(DEVICE)\n",
    "\n",
    "# Â∞ÅË£Ö forward\n",
    "def forward_features(x):\n",
    "    return backbone(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d700267-54ba-4340-8f96-e6164d179571",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 5. ÊçüÂ§±ÂáΩÊï∞ (Á±ªÂà´Âä†ÊùÉ CE) & ‰ºòÂåñÂô® & Ë∞ÉÂ∫¶Âô®\n",
    "# --------------------------------------------------------------\n",
    "# 5.1 Á±ªÂà´ÊùÉÈáç (Áà∂Á±ª)\n",
    "cnt_parent = Counter(train_ds.p_labels.tolist())\n",
    "tot_samples = len(train_ds)\n",
    "w_parent = torch.tensor([tot_samples / cnt_parent[i] for i in range(NUM_PARENT)], dtype=torch.float).to(DEVICE)\n",
    "criterion_parent = nn.CrossEntropyLoss(weight=w_parent, label_smoothing=0.1)\n",
    "\n",
    "# 5.2 Â≠êÁ±ªÂèØÈÄâÂä†ÊùÉ (ÂÆûÈôÖÊ≤°‰ΩøÁî®)\n",
    "criterion_child  = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# 5.3 Optimizer (ÂàÜÁªÑ lr)\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": backbone.parameters(),   \"lr\": BASE_LR * 0.2},\n",
    "    {\"params\": head_parent.parameters(),\"lr\": BASE_LR},\n",
    "    {\"params\": head_child.parameters(), \"lr\": BASE_LR}\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# 5.4 Scheduler: Linear Warmup -> Cosine\n",
    "def lr_lambda(cur_epoch):\n",
    "    if cur_epoch < WARM_EPOCHS:\n",
    "        return float(cur_epoch + 1) / WARM_EPOCHS\n",
    "    return 0.5 * (1 + math.cos(math.pi * (cur_epoch - WARM_EPOCHS) / (NUM_EPOCHS - WARM_EPOCHS)))\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "scaler = GradScaler()\n",
    "ema    = ExponentialMovingAverage([*backbone.parameters(), *head_parent.parameters(), *head_child.parameters()], decay=EMA_DECAY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db820305-cf2a-4c71-ba28-5e97ca4af2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 6. MixUp / CutMix Â∑•ÂÖ∑\n",
    "# --------------------------------------------------------------\n",
    "def rand_bbox(size, lam):\n",
    "    H, W = size[2], size[3]\n",
    "    cut_rat = math.sqrt(1. - lam)\n",
    "    cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    x1, y1 = np.clip(cx - cut_w // 2, 0, W), np.clip(cy - cut_h // 2, 0, H)\n",
    "    x2, y2 = np.clip(cx + cut_w // 2, 0, W), np.clip(cy + cut_h // 2, 0, H)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def mixup_cutmix(images, labels, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    bs   = images.size(0)\n",
    "    idx  = torch.randperm(bs, device=images.device)\n",
    "    if random.random() < 0.5:  # MixUp\n",
    "        mixed = lam * images + (1 - lam) * images[idx]\n",
    "    else:                      # CutMix\n",
    "        x1,y1,x2,y2 = rand_bbox(images.size(), lam)\n",
    "        mixed = images.clone()\n",
    "        mixed[:, :, y1:y2, x1:x2] = images[idx, :, y1:y2, x1:x2]\n",
    "        lam = 1 - ((x2-x1)*(y2-y1)/(images.size(-1)*images.size(-2)))\n",
    "    return mixed, labels, labels[idx], lam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc1492a-d520-4023-bcdb-c77f635f1c7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 7. ËØÑ‰º∞ÂáΩÊï∞ (‰ΩøÁî® EMA ÊùÉÈáç)\n",
    "# --------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    backbone.eval(); head_parent.eval(); head_child.eval()\n",
    "    totals, corrects, loss_sum = 0, 0, 0.0\n",
    "    for imgs, p_lbl, _ in val_dl:\n",
    "        imgs, p_lbl = imgs.to(DEVICE), p_lbl.to(DEVICE)\n",
    "        with autocast():\n",
    "            feats = forward_features(imgs)\n",
    "            logits = head_parent(feats)\n",
    "            loss   = criterion_parent(logits, p_lbl)\n",
    "        loss_sum += loss.item() * imgs.size(0)\n",
    "        corrects += (logits.argmax(1) == p_lbl).sum().item()\n",
    "        totals   += imgs.size(0)\n",
    "    return loss_sum / totals, corrects / totals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542d0d4-79f7-4d95-abc7-69271207c861",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:57<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E01] lr=8.00e-06 | train=0.9540 | p[loss=0.8023, acc=69.30%] | c[loss=10.0139, acc=0.01%] | time=1164.7s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3504  643  853]\n",
      " [ 917 3565  518]\n",
      " [1201  473 3326]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n",
      "  ‚úÖ ÊúÄÂº∫Â≠êÁ±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[2/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:47<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E02] lr=8.00e-06 | train=0.8902 | p[loss=0.7573, acc=72.65%] | c[loss=10.0196, acc=0.02%] | time=1153.5s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3576  659  765]\n",
      " [ 769 3825  406]\n",
      " [1003  500 3497]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n",
      "  ‚úÖ ÊúÄÂº∫Â≠êÁ±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[3/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:48<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E03] lr=8.00e-06 | train=0.8672 | p[loss=0.7311, acc=74.37%] | c[loss=10.0224, acc=0.01%] | time=1154.0s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3631  614  755]\n",
      " [ 693 3910  397]\n",
      " [ 929  457 3614]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[4/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:48<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E04] lr=8.00e-06 | train=0.8491 | p[loss=0.7112, acc=75.57%] | c[loss=10.0247, acc=0.01%] | time=1154.1s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3697  600  703]\n",
      " [ 648 3965  387]\n",
      " [ 910  416 3674]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[5/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E05] lr=8.00e-06 | train=0.8263 | p[loss=0.6974, acc=76.46%] | c[loss=10.0251, acc=0.01%] | time=1148.9s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3740  591  669]\n",
      " [ 615 4030  355]\n",
      " [ 902  399 3699]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[6/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E06] lr=1.60e-05 | train=0.8176 | p[loss=0.6884, acc=77.30%] | c[loss=10.4327, acc=0.09%] | time=1149.4s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3775  557  668]\n",
      " [ 607 4040  353]\n",
      " [ 833  387 3780]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n",
      "  ‚úÖ ÊúÄÂº∫Â≠êÁ±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[7/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E07] lr=2.40e-05 | train=0.8178 | p[loss=0.6787, acc=77.87%] | c[loss=10.6438, acc=0.09%] | time=1149.0s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3837  514  649]\n",
      " [ 609 4040  351]\n",
      " [ 854  343 3803]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[8/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E08] lr=3.20e-05 | train=0.8133 | p[loss=0.6687, acc=78.59%] | c[loss=10.7988, acc=0.05%] | time=1148.2s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3890  467  643]\n",
      " [ 599 4039  362]\n",
      " [ 823  318 3859]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[9/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E09] lr=4.00e-05 | train=0.8036 | p[loss=0.6586, acc=79.52%] | c[loss=10.9657, acc=0.05%] | time=1148.5s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3904  489  607]\n",
      " [ 564 4098  338]\n",
      " [ 768  306 3926]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[10/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E10] lr=4.00e-05 | train=0.7966 | p[loss=0.6525, acc=79.93%] | c[loss=11.1043, acc=0.01%] | time=1148.4s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3942  456  602]\n",
      " [ 561 4098  341]\n",
      " [ 761  290 3949]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[11/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E11] lr=4.00e-05 | train=0.7835 | p[loss=0.6458, acc=80.49%] | c[loss=11.2092, acc=0.03%] | time=1148.6s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3941  460  599]\n",
      " [ 535 4132  333]\n",
      " [ 713  287 4000]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[12/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E12] lr=3.99e-05 | train=0.7553 | p[loss=0.6408, acc=80.71%] | c[loss=11.3061, acc=0.03%] | time=1148.2s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3940  462  598]\n",
      " [ 522 4143  335]\n",
      " [ 699  278 4023]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[13/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E13] lr=3.97e-05 | train=0.7320 | p[loss=0.6374, acc=81.05%] | c[loss=11.3469, acc=0.03%] | time=1149.1s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3919  476  605]\n",
      " [ 488 4196  316]\n",
      " [ 675  282 4043]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[14/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E14] lr=3.95e-05 | train=0.7093 | p[loss=0.6384, acc=81.12%] | c[loss=11.3650, acc=0.01%] | time=1148.8s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3912  456  632]\n",
      " [ 494 4188  318]\n",
      " [ 663  269 4068]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[15/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:45<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E15] lr=3.92e-05 | train=0.7020 | p[loss=0.6401, acc=81.47%] | c[loss=11.4073, acc=0.02%] | time=1147.8s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3910  443  647]\n",
      " [ 468 4222  310]\n",
      " [ 638  274 4088]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[16/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E16] lr=3.88e-05 | train=0.6798 | p[loss=0.6430, acc=81.71%] | c[loss=11.4206, acc=0.03%] | time=1148.3s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3906  441  653]\n",
      " [ 466 4233  301]\n",
      " [ 616  266 4118]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[17/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E17] lr=3.84e-05 | train=0.6692 | p[loss=0.6463, acc=81.53%] | c[loss=11.4367, acc=0.03%] | time=1148.6s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3882  461  657]\n",
      " [ 461 4224  315]\n",
      " [ 614  262 4124]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[18/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E18] lr=3.79e-05 | train=0.6578 | p[loss=0.6483, acc=81.72%] | c[loss=11.4240, acc=0.03%] | time=1148.7s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3886  439  675]\n",
      " [ 445 4238  317]\n",
      " [ 603  263 4134]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[19/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E19] lr=3.74e-05 | train=0.6484 | p[loss=0.6516, acc=81.55%] | c[loss=11.4160, acc=0.03%] | time=1149.3s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3857  452  691]\n",
      " [ 446 4233  321]\n",
      " [ 589  268 4143]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[20/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:45<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E20] lr=3.68e-05 | train=0.6377 | p[loss=0.6534, acc=81.61%] | c[loss=11.4204, acc=0.03%] | time=1148.1s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3844  445  711]\n",
      " [ 430 4241  329]\n",
      " [ 588  256 4156]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[21/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E21] lr=3.62e-05 | train=0.6245 | p[loss=0.6549, acc=81.77%] | c[loss=11.4018, acc=0.03%] | time=1148.5s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3828  449  723]\n",
      " [ 421 4246  333]\n",
      " [ 560  248 4192]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[22/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E22] lr=3.55e-05 | train=0.6249 | p[loss=0.6567, acc=81.85%] | c[loss=11.3920, acc=0.03%] | time=1148.5s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3835  444  721]\n",
      " [ 419 4243  338]\n",
      " [ 550  251 4199]]\n",
      "  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[23/60]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1598/1598 [17:46<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E23] lr=3.47e-05 | train=0.6192 | p[loss=0.6580, acc=81.79%] | c[loss=11.3926, acc=0.03%] | time=1147.9s\n",
      "‚Ü≥ Parent Confusion Matrix:\n",
      " [[3832  445  723]\n",
      " [ 425 4235  340]\n",
      " [ 548  250 4202]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[24/60]:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                     | 313/1598 [03:30<14:15,  1.50it/s]"
     ]
    }
   ],
   "source": [
    "# ==== 5. Train / Eval with Logging, EMA, EarlyStopping, Resume ======================\n",
    "best_p_acc, best_c_acc = 0.0, 0.0\n",
    "patience, non_improve = 5, 0\n",
    "\n",
    "CKPT_DIR = \"checkpoint\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "start_epoch = 1\n",
    "\n",
    "# === Resume from checkpoint ===\n",
    "ckpt_list = sorted(glob.glob(os.path.join(CKPT_DIR, \"best_parent_*.pth\")), key=os.path.getmtime)\n",
    "if ckpt_list:\n",
    "    latest = ckpt_list[-1]\n",
    "    print(f\"üîÑ Resumed from {latest}\")\n",
    "    ckpt = torch.load(latest, map_location=DEVICE)\n",
    "    backbone.load_state_dict(ckpt[\"backbone\"])\n",
    "    head_parent.load_state_dict(ckpt[\"head_p\"])\n",
    "    if \"head_c\" in ckpt: head_child.load_state_dict(ckpt[\"head_c\"])\n",
    "    if \"opt\" in ckpt: optimizer.load_state_dict(ckpt[\"opt\"])\n",
    "    if \"sched\" in ckpt: scheduler.load_state_dict(ckpt[\"sched\"])\n",
    "    if \"scaler\" in ckpt: scaler.load_state_dict(ckpt[\"scaler\"])\n",
    "    if \"ema\" in ckpt: ema.load_state_dict(ckpt[\"ema\"])\n",
    "    best_p_acc = ckpt.get(\"p_acc\", best_p_acc)\n",
    "    best_c_acc = ckpt.get(\"c_acc\", best_c_acc)\n",
    "    start_epoch = ckpt.get(\"epoch\", start_epoch) + 1\n",
    "    print(f\"  ‚Üí start_epoch={start_epoch} | best_p_acc={best_p_acc:.4f} | best_c_acc={best_c_acc:.4f}\")\n",
    "\n",
    "# === CSV Logger ===\n",
    "log_file = pathlib.Path(\"train_log.csv\")\n",
    "with log_file.open(\"a\", newline=\"\") as log_fh:\n",
    "    logger = csv.writer(log_fh)\n",
    "    if log_file.stat().st_size == 0:\n",
    "        logger.writerow([\"epoch\",\"lr\",\"train_loss\",\"p_loss\",\"p_acc\",\"c_loss\",\"c_acc\",\"time_sec\"])\n",
    "\n",
    "    def evaluate():\n",
    "        backbone.eval(); head_parent.eval(); head_child.eval()\n",
    "        p_correct = c_correct = total = 0\n",
    "        p_loss_sum = c_loss_sum = 0.0\n",
    "        all_p_preds, all_p_gts = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, y_p, y_c in val_dl:\n",
    "                imgs, y_p, y_c = imgs.to(DEVICE), y_p.to(DEVICE), y_c.to(DEVICE)\n",
    "                with autocast():\n",
    "                    feats = forward_features(imgs)\n",
    "                    logits_p = head_parent(feats)\n",
    "                    logits_c = head_child(feats)\n",
    "                    loss_p = criterion_parent(logits_p, y_p)\n",
    "                    loss_c = criterion_child(logits_c, y_c)\n",
    "\n",
    "                p_loss_sum += loss_p.item() * y_p.size(0)\n",
    "                c_loss_sum += loss_c.item() * y_c.size(0)\n",
    "                pred_p = logits_p.argmax(1)\n",
    "                p_correct += (pred_p == y_p).sum().item()\n",
    "                c_correct += (logits_c.argmax(1) == y_c).sum().item()\n",
    "                total += y_p.size(0)\n",
    "\n",
    "                all_p_preds.extend(pred_p.cpu().tolist())\n",
    "                all_p_gts.extend(y_p.cpu().tolist())\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(all_p_gts, all_p_preds, labels=[0,1,2])\n",
    "        return p_loss_sum/total, p_correct/total, c_loss_sum/total, c_correct/total, cm\n",
    "\n",
    "    # === Training Loop ===\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS + 1):\n",
    "        t0 = time.time()\n",
    "        backbone.train(); head_parent.train(); head_child.train()\n",
    "        run_loss, tot = 0.0, 0\n",
    "\n",
    "        use_mix = epoch <= MIXUP_CUTMIX_STOP\n",
    "        for imgs, y_p, y_c in tqdm(train_dl, desc=f\"Epoch[{epoch}/{NUM_EPOCHS}]\", ncols=120):\n",
    "            imgs, y_p, y_c = imgs.to(DEVICE), y_p.to(DEVICE), y_c.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_mix:\n",
    "                imgs, y_p_a, y_p_b, lam = mixup_cutmix(imgs, y_p)\n",
    "\n",
    "            with autocast():\n",
    "                feats = forward_features(imgs)\n",
    "                logits_p = head_parent(feats)\n",
    "                logits_c = head_child(feats)\n",
    "\n",
    "                loss_p = (lam * criterion_parent(logits_p, y_p_a) + (1 - lam) * criterion_parent(logits_p, y_p_b)) if use_mix else criterion_parent(logits_p, y_p)\n",
    "                child_weight = max(0.0, (epoch - WARM_EPOCHS) / (NUM_EPOCHS - WARM_EPOCHS))\n",
    "                loss_c = criterion_child(logits_c, y_c)\n",
    "                loss = (1 - child_weight) * loss_p + child_weight * loss_c\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(backbone.parameters(), MAX_GRAD_NORM)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            ema.update()\n",
    "\n",
    "            run_loss += loss_p.item() * imgs.size(0)\n",
    "            tot += imgs.size(0)\n",
    "\n",
    "        if epoch > WARM_EPOCHS:\n",
    "            scheduler.step()\n",
    "\n",
    "        # === EMA È™åËØÅ ===\n",
    "        with ema.average_parameters():\n",
    "            p_val_loss, p_val_acc, c_val_loss, c_val_acc, cm = evaluate()\n",
    "\n",
    "        train_loss = run_loss / tot\n",
    "        elapsed = time.time() - t0\n",
    "        cur_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        print(f\"[E{epoch:02d}] lr={cur_lr:.2e} | train={train_loss:.4f} | p[loss={p_val_loss:.4f}, acc={p_val_acc*100:.2f}%] | c[loss={c_val_loss:.4f}, acc={c_val_acc*100:.2f}%] | time={elapsed:.1f}s\")\n",
    "        print(\"‚Ü≥ Parent Confusion Matrix:\\n\", cm)\n",
    "\n",
    "        logger.writerow([epoch, f\"{cur_lr:.2e}\", f\"{train_loss:.4f}\", f\"{p_val_loss:.4f}\", f\"{p_val_acc:.4f}\", f\"{c_val_loss:.4f}\", f\"{c_val_acc:.4f}\", f\"{elapsed:.1f}\"])\n",
    "        log_fh.flush()\n",
    "\n",
    "        improved = False\n",
    "        if p_val_acc > best_p_acc:\n",
    "            best_p_acc, improved = p_val_acc, True\n",
    "            torch.save({\n",
    "                \"backbone\": backbone.state_dict(),\n",
    "                \"head_p\": head_parent.state_dict(),\n",
    "                \"head_c\": head_child.state_dict(),\n",
    "                \"opt\": optimizer.state_dict(),\n",
    "                \"sched\": scheduler.state_dict(),\n",
    "                \"scaler\": scaler.state_dict(),\n",
    "                \"ema\": ema.state_dict(),\n",
    "                \"p_acc\": best_p_acc,\n",
    "                \"c_acc\": c_val_acc,\n",
    "                \"epoch\": epoch\n",
    "            }, os.path.join(CKPT_DIR, f\"best_parent_{best_p_acc:.4f}.pth\"))\n",
    "            print(\"  ‚úÖ ÊúÄÂº∫Áà∂Á±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\")\n",
    "        if c_val_acc > best_c_acc:\n",
    "            best_c_acc = c_val_acc\n",
    "            torch.save({\n",
    "                \"backbone\": backbone.state_dict(),\n",
    "                \"head_c\": head_child.state_dict(),\n",
    "                \"c_acc\": best_c_acc\n",
    "            }, os.path.join(CKPT_DIR, f\"best_child_{best_c_acc:.4f}.pth\"))\n",
    "            print(\"  ‚úÖ ÊúÄÂº∫Â≠êÁ±ªÊ®°ÂûãÂ∑≤Êõ¥Êñ∞\")\n",
    "\n",
    "        non_improve = 0 if improved else non_improve + 1\n",
    "        if non_improve >= patience:\n",
    "            print(f\"‚èπÔ∏è Early stopping at epoch {epoch} after {patience} non-improving epochs.\")\n",
    "            break\n",
    "\n",
    "print(f\"‚úÖ Training Finished | Best Parent Acc={best_p_acc:.4f} | Best Child Acc={best_c_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da564dd-23fb-49e5-a15d-338b48030271",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Generating submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 235/235 [20:49<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 9. Êé®ÁêÜÁîüÊàê submission.csv (EMA ÊùÉÈáç + Â§öÂ∞∫Â∫¶Ê∞¥Âπ≥ÁøªËΩ¨ TTA)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n==> Generating submission.csv\")\n",
    "CKPT_DIR = \"checkpoint\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "#state = torch.load(\"best_parent_0.8185.pth\", map_location=DEVICE)\n",
    "best_ckpt = sorted(os.listdir(CKPT_DIR))[-1]\n",
    "state = torch.load(os.path.join(CKPT_DIR, best_ckpt), map_location=DEVICE)\n",
    "\n",
    "backbone.load_state_dict(state[\"backbone\"]); head_parent.load_state_dict(state[\"head_p\"])\n",
    "ema.load_state_dict(state[\"ema\"])\n",
    "backbone.eval(); head_parent.eval()\n",
    "\n",
    "# TTA ÂèòÊç¢ (3 Â∞∫Â∫¶ √ó Â∑¶Âè≥ÁøªËΩ¨)\n",
    "SCALES = [224, 256, 288]\n",
    "tta_trans = []\n",
    "for s in SCALES:\n",
    "    for flip in [False, True]:\n",
    "        t = [T.Resize(s), T.CenterCrop(224)]\n",
    "        if flip: t.append(T.RandomHorizontalFlip(p=1.0))\n",
    "        t += [T.ToTensor(), T.Normalize(MEAN, STD)]\n",
    "        tta_trans.append(T.Compose(t))\n",
    "TTA_N = len(tta_trans)\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "ids = df_test[\"id\"].values\n",
    "out_ids, out_labels = [], []\n",
    "\n",
    "with torch.no_grad(), ema.average_parameters(), autocast():\n",
    "    for i in tqdm(range(0, len(ids), BATCH_SIZE), ncols=120, desc=\"Inference\"):\n",
    "        batch_ids = ids[i:i+BATCH_SIZE]\n",
    "        imgs_all = []\n",
    "        for fname in batch_ids:\n",
    "            img = Image.open(os.path.join(TEST_IMGDIR, fname)).convert(\"RGB\")\n",
    "            imgs_all.extend([tf(img) for tf in tta_trans])\n",
    "        imgs_all = torch.stack(imgs_all).to(DEVICE)\n",
    "\n",
    "        feats = forward_features(imgs_all)\n",
    "        logits = head_parent(feats).view(len(batch_ids), TTA_N, NUM_PARENT)\n",
    "        logits = logits.mean(1)          # TTA Âπ≥Âùá\n",
    "        preds  = logits.argmax(1).cpu().numpy()\n",
    "\n",
    "        out_ids.extend(batch_ids)\n",
    "        out_labels.extend(preds.tolist())\n",
    "\n",
    "pd.DataFrame({\"id\": out_ids, \"label\": out_labels}).to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
